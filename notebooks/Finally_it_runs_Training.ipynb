{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Finally it runs Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPI5E5y0pujD"
      },
      "source": [
        "<p align=\"center\">\n",
        "    <a\n",
        "    href=\"https://youtu.be/dcb4Ckpkx2o\"\n",
        "    target=\"_blank\"\n",
        "    rel=\"noopener noreferrer\">\n",
        "        <img\n",
        "        alt=\"Night Sky Latent Walk\"\n",
        "        width=\"350\" height=\"350\"\n",
        "        src=\"https://github.com/ArthurFDLR/GANightSky/blob/main/.github/random_walk.gif?raw=true\">\n",
        "    </a>\n",
        "</p>\n",
        "\n",
        "# ðŸš€ StyleGan2-ADA for Google Colab\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktqaMJUZuOl7"
      },
      "source": [
        "1.   [Install StyleGAN2-ADA on your Google Drive](#scrollTo=5YcUMPQp6ipP)\n",
        "2.   [Train a custom model](#scrollTo=Ti11YiPAiQpb)\n",
        "3.   [Generate images from pre-trained model](#scrollTo=f0A9ZNtferpk)\n",
        "4.   [Latent space exploration](#scrollTo=5yG1UyHXXqsO)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YcUMPQp6ipP"
      },
      "source": [
        "## Install StyleGAN2-ADA on your Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI_i1MwgpzOD"
      },
      "source": [
        "StyleGAN2-ADA only works with Tensorflow 1. Run the next cell before anything else to make sure weâ€™re using TF1 and not TF2.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKYAU7Wub3WW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4bf672a-d093-4430-c85a-8d65b0f35cfd"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Thu Nov 25 16:06:11 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19_1uXab3gND"
      },
      "source": [
        "Then, mount your Drive to the Colab notebook: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxxYlEKI9Gis",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3563c68-6554-4ea0-8dd5-4e167c7d3ac6"
      },
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.mount(str(drive_path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epV6TDzAjox1"
      },
      "source": [
        "Finally, run this cell to install StyleGAN2-ADA on your Drive. If youâ€™ve already installed the repository, it will skip the installation process and only check for updates. If you havenâ€™t installed it, it will install all the necessary files. Beside, **in**, **out**, **datasets** and **training** folders are generated for data storage. Everything will be available on your Google Drive in the folder **StyleGAN2-ADA** even after closing this Notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HX77jscX2zV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b373d6-5911-4054-b272-3338868c5ad1"
      },
      "source": [
        "stylegan2_repo_url  = 'https://github.com/dvschultz/stylegan2-ada' # or https://github.com/NVlabs/stylegan2-ada\n",
        "project_path        = drive_path / 'MyDrive' / 'StyleGAN2-ADA'\n",
        "stylegan2_repo_path = project_path / 'stylegan2-ada'\n",
        "\n",
        "# Create project folder if inexistant\n",
        "if not project_path.is_dir():\n",
        "    %mkdir \"{project_path}\"\n",
        "%cd \"{project_path}\"\n",
        "\n",
        "for dir in ['in', 'out', 'datasets', 'training']:\n",
        "    if not (project_path / dir).is_dir():\n",
        "        %mkdir {dir}\n",
        "if not (project_path / 'datasets' / 'source').is_dir():\n",
        "    %mkdir \"{project_path / 'datasets' / 'source'}\"\n",
        "\n",
        "# Download StyleGAN2-ada\n",
        "!git config --global user.name \"ArthurFDLR\"\n",
        "!git config --global user.email \"arthfind@gmail.com\"\n",
        "if stylegan2_repo_path.is_dir():\n",
        "    !git -C \"{stylegan2_repo_path}\" fetch origin\n",
        "    !git -C \"{stylegan2_repo_path}\" checkout origin/main -- *.py\n",
        "else:\n",
        "    print(\"Install StyleGAN2-ADA\")\n",
        "    !git clone {stylegan2_repo_url}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/StyleGAN2-ADA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti11YiPAiQpb"
      },
      "source": [
        "## Train a custom model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ioqYi9NzkUfG"
      },
      "source": [
        "Once you have installed StyleGAN2-ADA on your Google Drive and set up the working directory, you can upload your training dataset images in the associated folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlV5HIEqiZvu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60073172-d2bd-4364-a481-d8663d346c08"
      },
      "source": [
        "dataset_name = 'NightSky'\n",
        "datasets_source_path = project_path / 'datasets' / 'source' / (dataset_name + '.zip')\n",
        "if datasets_source_path.is_dir():\n",
        "    print(\"Dataset ready for import.\")\n",
        "else:\n",
        "    print('Upload your images dataset as {}'.format(datasets_source_path))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your images dataset as /content/drive/MyDrive/StyleGAN2-ADA/datasets/source/NightSky.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y1-tvr5617d"
      },
      "source": [
        "Unfortunately, large datasets might exceed the Google Drive quota after a few training batches. Indeed, StyleGAN2 download datasets multiple times during training. You might have to import your dataset in the local storage session. However, large files cannot be copy/paste from Drive *(Input/Output error)*. \n",
        "\n",
        "Run this cell to download your zipped dataset from your Drive and unzip it in the local session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQZGo4g5y7rh"
      },
      "source": [
        "#local_dataset_path = content_path / 'dataset'\n",
        "#if not local_dataset_path.is_dir():\n",
        "#   print(\"Importing dataset...\")\n",
        "#   %mkdir \"{local_dataset_path}\"\n",
        "#   %cp -a \"{project_path / 'datasets' / 'source' / (dataset_name + '.zip')}\" \"{local_dataset_path}\"\n",
        "#   print(\"Zip file succesfuly imported\")\n",
        "#else:\n",
        "#   print('Zip file allready imported')\n",
        "#import zipfile\n",
        "#with zipfile.ZipFile(str(local_dataset_path / (dataset_name + '.zip')), 'r') as zip_ref:\n",
        "#    zip_ref.extractall(str(local_dataset_path))\n",
        "#print('Extraction completed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bkPdyGWSQVX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeS9tDvt61VG"
      },
      "source": [
        "### Convert dataset to .tfrecords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q58MJbckLUc"
      },
      "source": [
        "Next, we need to convert our image dataset to a format that StyleGAN2-ADA can read:`.tfrecords`.\n",
        "\n",
        "This can take a while."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHmJJqwwMgir"
      },
      "source": [
        "local_images_path =\"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/NightSky\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1U1J0y9KiEo0"
      },
      "source": [
        "local_dataset_path = \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/tfr/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pjO_wFleMzsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55aa256a-2467-47b7-a749-cb6d1f72984b"
      },
      "source": [
        "!python \"{stylegan2_repo_path / 'dataset_tool.py'}\" create_from_images \\\n",
        "\"{local_dataset_path}\" \"{local_images_path}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/NightSky\"\n",
            "Creating dataset \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/tfr/\"\n",
            "/content/drive/MyDrive/StyleGAN2-ADA/stylegan2-ada/dataset_tool.py:97: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 387 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DvTupHzP2s_"
      },
      "source": [
        "There are numerous arguments to tune the training of your model. To obtain nice results, you will certainly have to experiment. Here are the most popular parameters:\n",
        "\n",
        "\n",
        "*   *mirror:* Should the images be mirrored vertically?\n",
        "*   *mirrory:* Should the images be mirrored horizontally?\n",
        "*   *snap:* How often should the model generate image samples and a network pickle (.pkl file)?\n",
        "*   *resume:* Network pickle to resume training from?\n",
        "\n",
        "To see all the options, run the following ```help``` cell.\n",
        "\n",
        "Please note that Google Colab Pro gives access to V100 GPUs, which drastically decreases (~3x) processing time over P100 GPUs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fxu7CA0Qb1Yd"
      },
      "source": [
        "!python \"{stylegan2_repo_path / 'train.py'}\" --help"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOftFoyiDU3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6053783d-6f95-48e1-9da7-c0518174b511"
      },
      "source": [
        "training_path = project_path / 'training' / dataset_name\n",
        "if not training_path.is_dir():\n",
        "    %mkdir \"{training_path}\"\n",
        "\n",
        "#how often should the model generate samples and a .pkl file\n",
        "snapshot_count = 10\n",
        "#should the images be mirrored left to right?\n",
        "mirrored = True\n",
        "#should the images be mirrored top to bottom?\n",
        "mirroredY = False\n",
        "#metrics? \n",
        "metric_list = None\n",
        "#augments\n",
        "augs = 'geom'\n",
        "\n",
        "#resume_from = 'brecahad512'\n",
        "resume_from = 'training/pickles/FreaGAN.pkl'\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'train.py'}\" --outdir=\"{training_path}\" \\\n",
        "    --data=\"{local_dataset_path}\" --resume=\"{resume_from}\" \\\n",
        "    --snap={snapshot_count} --augpipe={augs} \\\n",
        "    --mirror={mirrored} --mirrory={mirroredY} \\\n",
        "    --metrics={metric_list} #--dry-run"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 4294967296 bytes == 0x557c7dfda000 @  0x7f37df4f8001 0x7f37dc6fb54f 0x7f37dc74bb58 0x7f37dc74fb17 0x7f37dc7ee203 0x557c7718c544 0x557c7718c240 0x557c77200627 0x557c771faced 0x557c7718e48c 0x557c771cf159 0x557c771cc0a4 0x557c7718cd49 0x557c7720094f 0x557c771fa9ee 0x557c770cce2b 0x557c771fcfe4 0x557c771fa9ee 0x557c770cce2b 0x557c771fcfe4 0x557c771faced 0x557c770cce2b 0x557c771fcfe4 0x557c7718dafa 0x557c771fb915 0x557c771fa9ee 0x557c771fa6f3 0x557c772c44c2 0x557c772c483d 0x557c772c46e6 0x557c7729c163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557d7dfda000 @  0x7f37df4f61e7 0x7f37dc6fb46e 0x7f37dc74bc7b 0x7f37dc74c35f 0x7f37dc7ee103 0x557c7718c544 0x557c7718c240 0x557c77200627 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c7718dafa 0x557c771fb915 0x557c771fa9ee 0x557c7718dbda 0x557c771ffd00 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771faced 0x557c7718e48c 0x557c771cf159 0x557c771cc0a4 0x557c7718cd49 0x557c7720094f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557e7f28a000 @  0x7f37df4f61e7 0x7f37dc6fb46e 0x7f37dc74bc7b 0x7f37dc74c35f 0x7f37880fb235 0x7f3787a7e792 0x7f3787a7ed42 0x7f3787a37aee 0x557c7718c437 0x557c7718c240 0x557c772000f3 0x557c7718dafa 0x557c771fbc0d 0x557c771faced 0x557c770cceb0 0x557c771fcfe4 0x557c771fa9ee 0x557c7718dbda 0x557c771fbc0d 0x557c771faced 0x557c7718dbda 0x557c771fbc0d 0x557c7718dafa 0x557c771fbc0d 0x557c771fa9ee 0x557c7718e271 0x557c7718e698 0x557c771fcfe4 0x557c771fa9ee 0x557c7718dbda 0x557c771fb915\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.002\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 52.4288\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 10,\n",
            "  \"network_snapshot_ticks\": 10,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/tfr/\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/StyleGAN2-ADA/datasets/source/tfr/\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"use_raw\": false,\n",
            "    \"resolution\": 1024,\n",
            "    \"mirror_augment\": true,\n",
            "    \"mirror_augment_v\": false\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 4,\n",
            "  \"minibatch_gpu\": 4,\n",
            "  \"G_smoothing_kimg\": 1.25,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"training/pickles/FreaGAN.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/StyleGAN2-ADA/training/NightSky/00025-tfr-mirror-auto1-geom-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/StyleGAN2-ADA/training/NightSky/00025-tfr-mirror-auto1-geom-resumecustom\n",
            "Training data:     /content/drive/MyDrive/StyleGAN2-ADA/datasets/source/tfr/\n",
            "Training length:   25000 kimg\n",
            "Resolution:        1024\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557c7dcd8000 @  0x7f37df4f8001 0x7f37dc6fb54f 0x7f37dc74bb58 0x7f37dc74fb17 0x7f37dc7ee203 0x557c7718c544 0x557c7718c240 0x557c77200627 0x557c771faced 0x557c7718e48c 0x557c771cf159 0x557c771cc0a4 0x557c7718cd49 0x557c7720094f 0x557c771fa9ee 0x557c770cce2b 0x557c771fcfe4 0x557c771fa9ee 0x557c770cce2b 0x557c771fcfe4 0x557c771faced 0x557c770cce2b 0x557c771fcfe4 0x557c7718dafa 0x557c771fb915 0x557c771fa9ee 0x557c771fa6f3 0x557c772c44c2 0x557c772c483d 0x557c772c46e6 0x557c7729c163\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557f7f28a000 @  0x7f37df4f61e7 0x7f37dc6fb46e 0x7f37dc74bc7b 0x7f37dc74c35f 0x7f37dc7ee103 0x557c7718c544 0x557c7718c240 0x557c77200627 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c7718dafa 0x557c771fb915 0x557c771fa9ee 0x557c7718dbda 0x557c771ffd00 0x557c771fa9ee 0x557c7718dbda 0x557c771fc737 0x557c771faced 0x557c7718e48c 0x557c771cf159 0x557c771cc0a4 0x557c7718cd49 0x557c7720094f\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x557f7f28a000 @  0x7f37df4f61e7 0x7f37dc6fb46e 0x7f37dc74bc7b 0x7f37dc74c35f 0x7f37880fb235 0x7f3787a7e792 0x7f3787a7ed42 0x7f3787a37aee 0x557c7718c437 0x557c7718c240 0x557c772000f3 0x557c7718dafa 0x557c771fbc0d 0x557c771faced 0x557c770cceb0 0x557c771fcfe4 0x557c771fa9ee 0x557c7718dbda 0x557c771fbc0d 0x557c771faced 0x557c7718dbda 0x557c771fbc0d 0x557c7718dafa 0x557c771fbc0d 0x557c771fa9ee 0x557c7718e271 0x557c7718e698 0x557c771fcfe4 0x557c771fa9ee 0x557c7718dbda 0x557c771fb915\n",
            "Image shape: [3, 1024, 1024]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Compiling... Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Compiling... Loading... Done.\n",
            "Resuming from \"training/pickles/FreaGAN.pkl\"\n",
            "\n",
            "G                               Params    OutputShape          WeightShape     \n",
            "---                             ---       ---                  ---             \n",
            "latents_in                      -         (?, 512)             -               \n",
            "labels_in                       -         (?, 0)               -               \n",
            "epochs                          1         ()                   ()              \n",
            "epochs_1                        1         ()                   ()              \n",
            "G_mapping/Normalize             -         (?, 512)             -               \n",
            "G_mapping/Dense0                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Dense1                262656    (?, 512)             (512, 512)      \n",
            "G_mapping/Broadcast             -         (?, 18, 512)         -               \n",
            "dlatent_avg                     -         (512,)               -               \n",
            "Truncation/Lerp                 -         (?, 18, 512)         -               \n",
            "G_synthesis/4x4/Const           8192      (?, 512, 4, 4)       (1, 512, 4, 4)  \n",
            "G_synthesis/4x4/Conv            2622465   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "G_synthesis/4x4/ToRGB           264195    (?, 3, 4, 4)         (1, 1, 512, 3)  \n",
            "G_synthesis/8x8/Conv0_up        2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Conv1           2622465   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "G_synthesis/8x8/Upsample        -         (?, 3, 8, 8)         -               \n",
            "G_synthesis/8x8/ToRGB           264195    (?, 3, 8, 8)         (1, 1, 512, 3)  \n",
            "G_synthesis/16x16/Conv0_up      2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Conv1         2622465   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "G_synthesis/16x16/Upsample      -         (?, 3, 16, 16)       -               \n",
            "G_synthesis/16x16/ToRGB         264195    (?, 3, 16, 16)       (1, 1, 512, 3)  \n",
            "G_synthesis/32x32/Conv0_up      2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Conv1         2622465   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "G_synthesis/32x32/Upsample      -         (?, 3, 32, 32)       -               \n",
            "G_synthesis/32x32/ToRGB         264195    (?, 3, 32, 32)       (1, 1, 512, 3)  \n",
            "G_synthesis/64x64/Conv0_up      2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Conv1         2622465   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "G_synthesis/64x64/Upsample      -         (?, 3, 64, 64)       -               \n",
            "G_synthesis/64x64/ToRGB         264195    (?, 3, 64, 64)       (1, 1, 512, 3)  \n",
            "G_synthesis/128x128/Conv0_up    1442561   (?, 256, 128, 128)   (3, 3, 512, 256)\n",
            "G_synthesis/128x128/Conv1       721409    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "G_synthesis/128x128/Upsample    -         (?, 3, 128, 128)     -               \n",
            "G_synthesis/128x128/ToRGB       132099    (?, 3, 128, 128)     (1, 1, 256, 3)  \n",
            "G_synthesis/256x256/Conv0_up    426369    (?, 128, 256, 256)   (3, 3, 256, 128)\n",
            "G_synthesis/256x256/Conv1       213249    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "G_synthesis/256x256/Upsample    -         (?, 3, 256, 256)     -               \n",
            "G_synthesis/256x256/ToRGB       66051     (?, 3, 256, 256)     (1, 1, 128, 3)  \n",
            "G_synthesis/512x512/Conv0_up    139457    (?, 64, 512, 512)    (3, 3, 128, 64) \n",
            "G_synthesis/512x512/Conv1       69761     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "G_synthesis/512x512/Upsample    -         (?, 3, 512, 512)     -               \n",
            "G_synthesis/512x512/ToRGB       33027     (?, 3, 512, 512)     (1, 1, 64, 3)   \n",
            "G_synthesis/1024x1024/Conv0_up  51297     (?, 32, 1024, 1024)  (3, 3, 64, 32)  \n",
            "G_synthesis/1024x1024/Conv1     25665     (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "G_synthesis/1024x1024/Upsample  -         (?, 3, 1024, 1024)   -               \n",
            "G_synthesis/1024x1024/ToRGB     16515     (?, 3, 1024, 1024)   (1, 1, 32, 3)   \n",
            "---                             ---       ---                  ---             \n",
            "Total                           28794126                                       \n",
            "\n",
            "\n",
            "D                     Params    OutputShape          WeightShape     \n",
            "---                   ---       ---                  ---             \n",
            "images_in             -         (?, 3, 1024, 1024)   -               \n",
            "labels_in             -         (?, 0)               -               \n",
            "1024x1024/FromRGB     128       (?, 32, 1024, 1024)  (1, 1, 3, 32)   \n",
            "1024x1024/Conv0       9248      (?, 32, 1024, 1024)  (3, 3, 32, 32)  \n",
            "1024x1024/Conv1_down  18496     (?, 64, 512, 512)    (3, 3, 32, 64)  \n",
            "1024x1024/Skip        2048      (?, 64, 512, 512)    (1, 1, 32, 64)  \n",
            "512x512/Conv0         36928     (?, 64, 512, 512)    (3, 3, 64, 64)  \n",
            "512x512/Conv1_down    73856     (?, 128, 256, 256)   (3, 3, 64, 128) \n",
            "512x512/Skip          8192      (?, 128, 256, 256)   (1, 1, 64, 128) \n",
            "256x256/Conv0         147584    (?, 128, 256, 256)   (3, 3, 128, 128)\n",
            "256x256/Conv1_down    295168    (?, 256, 128, 128)   (3, 3, 128, 256)\n",
            "256x256/Skip          32768     (?, 256, 128, 128)   (1, 1, 128, 256)\n",
            "128x128/Conv0         590080    (?, 256, 128, 128)   (3, 3, 256, 256)\n",
            "128x128/Conv1_down    1180160   (?, 512, 64, 64)     (3, 3, 256, 512)\n",
            "128x128/Skip          131072    (?, 512, 64, 64)     (1, 1, 256, 512)\n",
            "64x64/Conv0           2359808   (?, 512, 64, 64)     (3, 3, 512, 512)\n",
            "64x64/Conv1_down      2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "64x64/Skip            262144    (?, 512, 32, 32)     (1, 1, 512, 512)\n",
            "32x32/Conv0           2359808   (?, 512, 32, 32)     (3, 3, 512, 512)\n",
            "32x32/Conv1_down      2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "32x32/Skip            262144    (?, 512, 16, 16)     (1, 1, 512, 512)\n",
            "16x16/Conv0           2359808   (?, 512, 16, 16)     (3, 3, 512, 512)\n",
            "16x16/Conv1_down      2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "16x16/Skip            262144    (?, 512, 8, 8)       (1, 1, 512, 512)\n",
            "8x8/Conv0             2359808   (?, 512, 8, 8)       (3, 3, 512, 512)\n",
            "8x8/Conv1_down        2359808   (?, 512, 4, 4)       (3, 3, 512, 512)\n",
            "8x8/Skip              262144    (?, 512, 4, 4)       (1, 1, 512, 512)\n",
            "4x4/MinibatchStddev   -         (?, 513, 4, 4)       -               \n",
            "4x4/Conv              2364416   (?, 512, 4, 4)       (3, 3, 513, 512)\n",
            "4x4/Dense0            4194816   (?, 512)             (8192, 512)     \n",
            "Output                513       (?, 1)               (512, 1)        \n",
            "---                   ---       ---                  ---             \n",
            "Total                 29012513                                       \n",
            "\n",
            "Exporting sample images...\n",
            "Replicating networks across 1 GPUs...\n",
            "Initializing augmentations...\n",
            "Setting up optimizers...\n",
            "Constructing training graph...\n",
            "Finalizing training ops...\n",
            "Initializing metrics...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 2m 16s       sec/tick 27.1    sec/kimg 1693.78 maintenance 108.7  gpumem 10.1  augment 0.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXWUPhXt1eX"
      },
      "source": [
        "%pip install opensimplex\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images --help "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sp8QIzbyfC2"
      },
      "source": [
        "from numpy import random\n",
        "seed_init = random.randint(10000)\n",
        "nbr_images = 6\n",
        "\n",
        "generation_from = 'training/NightSky/00024-tfr-mirror-auto1-geom-resumecustom/network-snapshot-000000.pkl'\n",
        "\n",
        "!python \"{stylegan2_repo_path / 'generate.py'}\" generate-images \\\n",
        "    --outdir=\"{project_path / 'out'}\" --trunc=0.7 \\\n",
        "    --seeds={seed_init}-{seed_init+nbr_images-1} --create-grid \\\n",
        "    --network={generation_from}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg3oo2bZyfxQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}